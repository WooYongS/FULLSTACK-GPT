import streamlit as st
import requests
from bs4 import BeautifulSoup
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import SitemapLoader
from langchain.vectorstores.faiss import FAISS
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.prompts import ChatPromptTemplate
import os

# âœ… Cloudflare ë¬¸ì„œ ì‚¬ì´íŠ¸ë§µ URL
SITEMAP_URL = "https://developers.cloudflare.com/sitemap-0.xml"

# âœ… Chatbot UIë¥¼ ìœ„í•œ Streamlit ì„¤ì •
st.set_page_config(page_title="SiteGPT - Cloudflare Docs", page_icon="â˜ï¸")

st.title("â˜ï¸ SiteGPT - Cloudflare Docs")
st.write("Ask me anything about Cloudflare's AI Gateway, Vectorize, or Workers AI.")

# âœ… ì‚¬ìš©ì API Key ì…ë ¥ë°›ê¸°
with st.sidebar:
    st.subheader("Settings")
    openai_api_key = st.text_input("Enter your OpenAI API Key", type="password")
    st.markdown("[GitHub Repository](https://github.com/your-repo-link)")

if not openai_api_key:
    st.error("ğŸš¨ Please enter your OpenAI API Key to use SiteGPT.")
    st.stop()


# âœ… Sitemapì—ì„œ Cloudflare ë¬¸ì„œ URL ì¶”ì¶œ
@st.cache_data(show_spinner="ğŸ”„ Loading Cloudflare Documentation...")
def extract_urls_from_sitemap(sitemap_url):
    try:
        response = requests.get(sitemap_url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "xml")
        urls = [loc.text for loc in soup.find_all("loc")]
        # AI Gateway, Vectorize, Workers AI ë¬¸ì„œë§Œ í•„í„°ë§
        filtered_urls = [
            url
            for url in urls
            if any(
                product in url for product in ["ai-gateway", "vectorize", "workers-ai"]
            )
        ]
        return filtered_urls
    except Exception as e:
        st.error(f"ğŸš¨ Failed to retrieve sitemap: {e}")
        return []


# âœ… ì‚¬ì´íŠ¸ë§µì—ì„œ ê°€ì ¸ì˜¨ ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥
@st.cache_resource(show_spinner="ğŸ”„ Indexing Cloudflare Documentation...")
def load_and_index_docs(urls):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

    docs = []
    for url in urls:
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, "html.parser")
            for tag in ["script", "style", "header", "footer", "nav"]:
                for element in soup.find_all(tag):
                    element.decompose()
            text = " ".join(soup.stripped_strings)
            chunks = text_splitter.split_text(text)
            docs.extend(
                [
                    Document(page_content=chunk, metadata={"source": url})
                    for chunk in chunks
                ]
            )
        except Exception as e:
            st.warning(f"âš  Failed to fetch page: {url} - {e}")

    # âœ… OpenAI Embeddingsì„ ì‚¬ìš©í•˜ì—¬ FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    vectorstore = FAISS.from_documents(docs, embeddings)
    return vectorstore


# âœ… Load Sitemap and Index Documents
doc_urls = extract_urls_from_sitemap(SITEMAP_URL)
if not doc_urls:
    st.error("ğŸš¨ No relevant Cloudflare documentation pages found in sitemap.")
    st.stop()

retriever = load_and_index_docs(doc_urls).as_retriever()

# âœ… ì±—ë´‡ì„ ìœ„í•œ LangChain RetrievalQA ì„¤ì •
llm = ChatOpenAI(model="gpt-4-turbo", temperature=0.5, openai_api_key=openai_api_key)

prompt_template = ChatPromptTemplate.from_template(
    """
    You are a helpful assistant that answers questions based on Cloudflare's documentation.
    Use the following context to provide accurate answers. If the information is not available, say "I don't know."
    
    Context: {context}
    
    Question: {question}
"""
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True,
)

# âœ… Streamlit Chat UI
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

user_input = st.chat_input("Ask a question about Cloudflare documentation...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("user"):
        st.markdown(user_input)

    with st.spinner("ğŸ” Searching documentation..."):
        response = qa_chain({"query": user_input})
        answer = response["result"]
        sources = response.get("source_documents", [])

    with st.chat_message("assistant"):
        st.markdown(answer)
        if sources:
            st.markdown("**Sources:**")
            for source in sources[:3]:  # ìµœëŒ€ 3ê°œì˜ ì¶œì²˜ í‘œì‹œ
                st.markdown(
                    f"- [{source.metadata['source']}]({source.metadata['source']})"
                )

    st.session_state.messages.append({"role": "assistant", "content": answer})

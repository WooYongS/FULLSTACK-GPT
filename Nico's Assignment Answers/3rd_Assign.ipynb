{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/ICE0208/a63490ad7163935be3dbfe66552e8237\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™” ë° ì„¤ì •\n",
    "\n",
    "# ChatOpenAI ìƒì„±ìë¥¼ ì´ìš©í•˜ì—¬ OpenAIì˜ GPT ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” ì‹œ ëª‡ëª‡ ì„¤ì •ì„ ì»¤ìŠ¤í…€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# í•´ì„¤ ì½”ë“œì—ì„œëŠ” temperature ë¥¼ ì¶”ê°€ë¡œ ì„¤ì •í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "# ConversationBufferMemoryë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "# return_messages=Trueë¡œ ì„¤ì •í•˜ì—¬ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ê¸°ë¡ì„ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ì˜ˆì œ ìƒì„±\n",
    "# ì„¸ ê°€ì§€ ì˜í™”ì— ëŒ€í•œ ì˜ˆì œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "# ê° ì˜ˆì œëŠ” ì˜í™” ì œëª©ê³¼ ê·¸ì— ëŒ€í•œ 3ê°œì˜ ì´ëª¨í‹°ì½˜ ë‹µë³€ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "# LLMì´ ì˜ˆì œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ë„ë¡ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "# ChatPromptTemplate.from_messagesë¥¼ ì´ìš©í•˜ì—¬ ì˜ˆì œ ëŒ€í™” ë©”ì‹œì§€ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# FewShotChatMessagePromptTemplateë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œ ëŒ€í™” ë©”ì‹œì§€ì™€ ì˜ˆì œ ë°ì´í„°ë¥¼ ê²°í•©í•˜ê³ , ìƒˆë¡œìš´ ì˜í™” ì œëª©ì— ëŒ€í•´ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€, ì˜ˆì œ í”„ë¡¬í”„íŠ¸(fewshot_chat_prompt), ëŒ€í™” ê¸°ë¡ í”Œë ˆì´ìŠ¤í™€ë”(MessagesPlaceholder), ê·¸ë¦¬ê³  ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "\n",
    "# ì²´ì¸ ì„¤ì •\n",
    "# RunnablePassthrough.assignì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ë¡œë“œ í•¨ìˆ˜ë¥¼ ì²´ì¸ì— ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "# final_promptì™€ llmì„ ì—°ê²°í•˜ì—¬ ìµœì¢… ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ í•¨ìˆ˜ (invoke_chain)\n",
    "# invoke_chain í•¨ìˆ˜ë¥¼ í†µí•´ ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„ ì²´ì¸ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "# ì €ì¥ëœ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# ì‘ë™ í…ŒìŠ¤íŠ¸\n",
    "# ì •ìƒì ì¸ ì‘ë™ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ë‘ ê°œì˜ ì˜í™”ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³ , ì²« ë²ˆì§¸ë¡œ ë¬¼ì–´ë³¸ ì˜í™”ì— ëŒ€í•œ ë‹µë³€ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\n",
    "# ì˜í™” ì œëª©ì— ëŒ€í•œ ë‹µë³€ì´ ì´ëª¨í‹°ì½˜ 3ê°œë¡œ êµ¬ì„±ëœ ê²ƒì„ ë³´ì•„ ì˜ˆì œê°€ ì˜ í•™ìŠµë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# ë˜í•œ ì²« ë²ˆì§¸ë¡œ ì§ˆë¬¸í•œ ì˜í™”ê°€ ë¬´ì—‡ì¸ì§€ì— ëŒ€í•œ ì •í™•í•œ ëŒ€ë‹µì„ í†µí•´ ë©”ëª¨ë¦¬ ì ìš©ì´ ì˜ ë˜ì—ˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# ê²°ë¡ \n",
    "# ì´ë²ˆ ì±Œë¦°ì§€ëŠ” ë©”ëª¨ë¦¬ê°€ ì ìš©ëœ LCEL ì²´ì¸ì„ êµ¬í˜„í•˜ì—¬, LLMì´ ëŒ€í™” ê¸°ë¡ì— ëŒ€í•œ ë§¥ë½ì„ ì´í•´í•˜ê³  ê·¸ì— ë§ëŠ” ì ì ˆí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•ì„ ì—°ìŠµí•˜ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤.\n",
    "# ë˜í•œ, ì²´ì¸ì— ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ ëª¨ë¸ì´ ë™ì¼í•œ í˜•ì‹ì˜ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ í•˜ëŠ” ì—°ìŠµë„ í•¨ê»˜ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì§€ë‚œ ì±Œë¦°ì§€ì—ì„œ í•™ìŠµí•œ ë‚´ìš©ì„ ë³µìŠµí•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"Spider Man\",\n",
    "        \"answer\": \"ğŸ•·ï¸ğŸ•¸ï¸ğŸ—½\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Iron Man\",\n",
    "        \"answer\": \"ğŸ¦¾ğŸ•¶ï¸ğŸ”¥\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Thor\",\n",
    "        \"answer\": \"âš¡ï¸ğŸ”¨ğŸŒ©ï¸\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"{question}\"), (\"ai\", \"{answer}\")]\n",
    ")\n",
    "\n",
    "fewshot_chat_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a movie expert. You know every movie. If a human tells you the title of the movie, you have to respond with 3 emoticons.\",\n",
    "        ),\n",
    "        fewshot_chat_prompt,\n",
    "        (\n",
    "            \"system\",\n",
    "            \"The above examples should not be provided to the user. The user can only be provided with the conversation record below. Please provide the information to the user using the record below.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | final_prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ğŸ‡ºğŸ‡¸â­ï¸ğŸ›¡ï¸'\n",
      "content='ğŸ•¶ï¸ğŸ’£ğŸ”'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Captain America\")\n",
    "invoke_chain(\"Mission Impossible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You asked about \"Captain America.\"'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What was the first movie I asked?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I am an AI assistant and do not have a personal name. How can I assist you further?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
